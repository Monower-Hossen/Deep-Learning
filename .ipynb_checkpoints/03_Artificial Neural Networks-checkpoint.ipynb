{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0895b93f-6842-4af4-9433-dfea5d680489",
   "metadata": {},
   "source": [
    "# Deep Learning 03: Artificial Neural Networks\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Artificial Neural Networks (ANNs) are computational models inspired by the biological neural systems of the human brain. They are widely used in machine learning and deep learning due to their capability to approximate complex, non-linear functions and learn from data adaptively. This paper presents a comprehensive theoretical discussion of Artificial Neural Networks, covering their architectural design, mathematical formulation, learning and training algorithms, advantages, limitations, and practical applications. The objective is to provide a structured and rigorous explanation suitable for academic and research contexts.\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Artificial Neural Networks constitute a fundamental class of models in modern artificial intelligence and machine learning. Unlike traditional algorithmic approaches that rely on explicitly programmed rules, ANNs learn patterns directly from data through iterative optimization of parameters. This data-driven learning capability makes ANNs particularly effective for problems involving high-dimensional data, non-linearity, and uncertainty.\n",
    "\n",
    "With advancements in computational power and optimization techniques, ANNs have become the foundation of deep learning architectures used in areas such as computer vision, speech recognition, natural language processing, and predictive analytics.\n",
    "\n",
    "\n",
    "## 2. Biological Motivation\n",
    "\n",
    "The design of Artificial Neural Networks is inspired by the structure and functioning of biological neurons. In biological systems, neurons receive electrical signals through dendrites, integrate them in the cell body, and transmit outputs via axons to other neurons. Learning occurs through the strengthening or weakening of synaptic connections.\n",
    "\n",
    "Similarly, artificial neurons receive numerical inputs, apply weighted summation, pass the result through an activation function, and produce an output. Learning is achieved by adjusting connection weights based on observed errors.\n",
    "\n",
    "\n",
    "## 3. Architecture of Artificial Neural Networks\n",
    "\n",
    "### 3.1 Artificial Neuron Model\n",
    "An artificial neuron is the fundamental processing unit of an ANN. It consists of:\n",
    "* **Input signals:** $x_1, x_2, \\dots, x_n$\n",
    "* **Weights:** $w_1, w_2, \\dots, w_n$\n",
    "* **Bias term:** $b$\n",
    "* **Activation function:** $f(\\cdot)$\n",
    "\n",
    "The neuron computes a weighted sum of inputs and applies a non-linear activation function.\n",
    "\n",
    "\n",
    "### 3.2 Layered Network Structure\n",
    "\n",
    "An ANN is typically organized into layers:\n",
    "\n",
    "1. **Input Layer**\n",
    "   Receives raw input features and passes them to the hidden layers.\n",
    "\n",
    "2. **Hidden Layer(s)**\n",
    "   Performs intermediate computations and feature transformations. A network may contain one or multiple hidden layers.\n",
    "\n",
    "3. **Output Layer**\n",
    "   Produces the final output, such as a class label or a continuous value.\n",
    "\n",
    "Based on the number of hidden layers, networks may be classified as shallow neural networks or deep neural networks.\n",
    "\n",
    "\n",
    "## 4. Mathematical Modeling of ANN\n",
    "\n",
    "### 4.1 Neuron Output Computation\n",
    "\n",
    "The linear combination of inputs for a neuron is defined as:\n",
    "\n",
    "$$ z = \\sum_{i=1}^{n} w_i x_i + b $$\n",
    "\n",
    "The output of the neuron is obtained by applying an activation function:\n",
    "\n",
    "$$ a = f(z) $$\n",
    "**Where:**\n",
    "\n",
    "* $x_i$ : Represents input features\n",
    "* $w_i$ : Denotes weights\n",
    "* $b$ : Is the bias term\n",
    "* $f(z)$ : Is the activation function\n",
    "* $a$ : Is the final neuron output (activation)\n",
    "\n",
    "\n",
    "### 4.2 Activation Functions\n",
    "\n",
    "Activation functions introduce non-linearity into the network, enabling the modeling of complex relationships.\n",
    "\n",
    "Common activation functions include:\n",
    "\n",
    "* **Sigmoid Function**\n",
    "  \n",
    "$$f(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "* **Hyperbolic Tangent (Tanh)**\n",
    "\n",
    "  $$f(z) = \\tanh(z)$$\n",
    "\n",
    "* **Rectified Linear Unit (ReLU)**\n",
    "  \n",
    "  $$ f(z) = \\max(0, z) $$\n",
    "\n",
    "## 5. Training and Learning Algorithms\n",
    "\n",
    "### 5.1 Forward Propagation\n",
    "\n",
    "Forward propagation refers to the process of passing input data through the network layer by layer to compute predicted outputs.\n",
    "\n",
    "\n",
    "### 5.2 Loss Function\n",
    "\n",
    "The loss function quantifies the discrepancy between predicted outputs and actual target values.\n",
    "\n",
    "Examples include:\n",
    "\n",
    "* **Mean Squared Error (MSE)** for regression:\n",
    "\n",
    "$$ L = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "  \n",
    "* **Binary Cross-Entropy Loss** for classification:\n",
    "\n",
    "$$ L = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[y_i \\log(\\hat{y}_i) + (1 - y_i)\\log(1 - \\hat{y}_i)\\right] $$\n",
    "### 5.3 Backpropagation Algorithm\n",
    "\n",
    "Backpropagation is the primary learning algorithm used to train ANNs. It computes the gradient of the loss function with respect to each weight using the chain rule of calculus.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w}$$\n",
    "\n",
    "This gradient is used to update the weights in the direction that minimizes the loss.\n",
    "\n",
    "\n",
    "### 5.4 Optimization Techniques\n",
    "\n",
    "Weights are updated using optimization algorithms such as:\n",
    "\n",
    "* Gradient Descent\n",
    "* Stochastic Gradient Descent (SGD)\n",
    "* Adam Optimizer\n",
    "* RMSprop\n",
    "\n",
    "The general weight update rule is:\n",
    "\n",
    "\n",
    "$$ w^{(t+1)} = w^{(t)} - \\eta \\frac{\\partial L}{\\partial w} $$\n",
    "\n",
    "where $\\eta$ is the learning rate.\n",
    "\n",
    "## 6. Advantages of Artificial Neural Networks\n",
    "\n",
    "* Ability to model complex, non-linear relationships\n",
    "* High predictive accuracy with sufficient data\n",
    "* Adaptive learning capability\n",
    "* Robustness to noisy and incomplete data\n",
    "\n",
    "## 7. Limitations of Artificial Neural Networks\n",
    "\n",
    "* High computational and memory requirements\n",
    "* Requirement of large labeled datasets\n",
    "* Difficulty in interpretability (black-box nature)\n",
    "* Risk of overfitting without proper regularization\n",
    "\n",
    "\n",
    "## 8. Applications of ANN\n",
    "\n",
    "Artificial Neural Networks are widely applied in various domains, including:\n",
    "\n",
    "* Image and facial recognition\n",
    "* Speech and handwriting recognition\n",
    "* Medical diagnosis and disease prediction\n",
    "* Fraud detection in financial systems\n",
    "* Recommendation systems\n",
    "* Time-series forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3345fb21-6b16-4b2d-9626-1f3d65ec6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf66e65b-1b38-4675-86fb-3200e29be0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5292329-26e4-4a7d-9f3f-2532adc3d3e3",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Import dataset\n",
    "2. Separate features (X) and target (y)\n",
    "3. Encode categorical variables (Gender, Geography)\n",
    "4. Perform Feature Scaling\n",
    "5. Split into training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf87a2b-7e85-4085-9cfd-98e8c7c22907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931cfe9f-777d-4df4-9dcb-515a8c91a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values   # Features\n",
    "y = dataset.iloc[:, -1].values    # Target (Exited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57423ad1-7216-4dfb-bb03-6cf11df188e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Sample:\n",
      " [[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n",
      " [608 'Spain' 'Female' 41 1 83807.86 1 0 1 112542.58]\n",
      " [502 'France' 'Female' 42 8 159660.8 3 1 0 113931.57]]\n",
      "y Sample:\n",
      " [1 0 1 0 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"X Sample:\\n\", X[:3])\n",
    "print(\"y Sample:\\n\", y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c2a35-5daf-4e72-8e47-7118adc02880",
   "metadata": {},
   "source": [
    "##  Encoding Categorical Data\n",
    "\n",
    "- **Label Encoding** for Gender\n",
    "- **OneHot Encoding** for Geography\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a053a045-80fe-4a40-805f-cf1f18d7f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding Gender\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44309da4-10df-41c9-9be8-be754829dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Geography\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(), [1])], \n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c099ff-860f-420d-97e1-11582b440220",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be125f9-cca1-4f23-84e3-0e1bc10072ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding:\n",
      " [[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n",
      " [0.0 0.0 1.0 608 0 41 1 83807.86 1 0 1 112542.58]\n",
      " [1.0 0.0 0.0 502 0 42 8 159660.8 3 1 0 113931.57]]\n"
     ]
    }
   ],
   "source": [
    "print(\"After Encoding:\\n\", X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f362e-8c60-4861-b013-61f76b0d4b3f",
   "metadata": {},
   "source": [
    "##  Splitting Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d834868c-fef7-4fd8-ab03-8b6cf7f7188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d24ad964-f5f9-4255-870f-2f3ef5fa3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (8000, 12)\n",
      "Test Shape: (2000, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape:\", X_train.shape)\n",
    "print(\"Test Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ad10b-9a8a-4ba6-a833-fb50e34dac95",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "ANNs converge faster with standardized inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4f1774-ee06-478a-9365-0f2c77f0569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c039b83-13d7-49e9-827f-edc7628ce134",
   "metadata": {},
   "source": [
    "#  Building the ANN\n",
    "We will start simple, then **add more layers** and compare performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b2c1c10-f867-47c9-88c2-da7626bd59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "# Input + First Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# Second Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fd35b-6bb8-463c-aac9-f8a205bfba53",
   "metadata": {},
   "source": [
    "#  Training the ANN\n",
    "\n",
    "- Optimizer: **Adam**\n",
    "- Loss Function: **Binary Crossentropy** (since this is binary classification)\n",
    "- Metric: **Accuracy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a89586a-ff45-4a32-b6f5-458dbc105554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile ANN\n",
    "ann.compile(optimizer = 'adam', \n",
    "            loss = 'binary_crossentropy', \n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50e52a6-96fc-44a7-9803-ba45747a4c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.7381\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4652 - accuracy: 0.8016\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4442 - accuracy: 0.8058\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4355 - accuracy: 0.8086\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8087\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.8123\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8176\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4085 - accuracy: 0.8226\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8311\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3841 - accuracy: 0.8384\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8428\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8462\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3633 - accuracy: 0.8465\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8499\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8524\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8535\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.8543\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3489 - accuracy: 0.8560\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8569\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3467 - accuracy: 0.8572\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8566\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8585\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8590\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8601\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8591\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8599\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8595\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3422 - accuracy: 0.8604\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8602\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.8625\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8606\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8622\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8604\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8624\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8605\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8602\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8602\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8612\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8609\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8621\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8593\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8610\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8608\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8612\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8620\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8621\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8612\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3386 - accuracy: 0.8616\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8604\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3381 - accuracy: 0.8624\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8621\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8616\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8616\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8635\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8614\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8624\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3374 - accuracy: 0.8626\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8611\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8612\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8618\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8608\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8618\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8625\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8615\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8620\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3365 - accuracy: 0.8618\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8624\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8626\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8622\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8615\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8622\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8631\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8611\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8635\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8620\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8615\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8629\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8622\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8624\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8618\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8616\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8610\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8631\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8611\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8618\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8620\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8616\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8627\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8620\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8633\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8630\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8625\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8622\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8608\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8622\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.8630\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8622\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8621\n"
     ]
    }
   ],
   "source": [
    "# Train ANN\n",
    "history = ann.fit(X_train, y_train, batch_size = 32, epochs = 100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49eeec0-eb6b-4954-afe9-986dadc902c2",
   "metadata": {},
   "source": [
    "#  Model Evaluation\n",
    "\n",
    "We will predict on the **Test set** and evaluate using:\n",
    "\n",
    "- Predictions\n",
    "- Confusion Matrix\n",
    "- Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46742beb-e4b0-4198-abf2-7577ca180f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e431c6f5-f87e-44b4-b474-fb6908ba5476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions vs actual\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cee2881-d9d3-4ca9-a6ad-aa31dfa62eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e35d0c1-d914-4863-b852-42c09a19f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1512   83]\n",
      " [ 189  216]]\n",
      "Accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ecf2c5-961c-4cbc-a1a2-2c5460da9641",
   "metadata": {},
   "source": [
    "#  Experimenting with More Layers\n",
    "We now add more 2 hidden layers and compare performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f66d32ae-aa19-4246-bd7c-9daa824c6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build deeper ANN\n",
    "ann_deep = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f938f869-306c-4d37-9d2c-561fa25a4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input + 3 Hidden Layers\n",
    "ann_deep.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "ann_deep.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "ann_deep.add(tf.keras.layers.Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f026ab8f-a6bf-47a8-a10c-e7032f13f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "ann_deep.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "595a2aeb-1e4c-475a-a537-ea74d0ab856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "ann_deep.compile(optimizer = 'adam', \n",
    "                 loss = 'binary_crossentropy', \n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87129bda-eaea-4ccd-82bd-2ac17ff062e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5528 - accuracy: 0.7794\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4606 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4403 - accuracy: 0.7962\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4323 - accuracy: 0.7979\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4267 - accuracy: 0.8018\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8171\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4110 - accuracy: 0.8240\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4047 - accuracy: 0.8263\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3986 - accuracy: 0.8279\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3932 - accuracy: 0.8271\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3878 - accuracy: 0.8303\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3826 - accuracy: 0.8322\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3787 - accuracy: 0.8315\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8306\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8380\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3655 - accuracy: 0.8491\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8519\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3587 - accuracy: 0.8543\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.8561\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8575\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3526 - accuracy: 0.8587\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8586\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8593\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8593\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8606\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8612\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8590\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8605\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3449 - accuracy: 0.8622\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3448 - accuracy: 0.8594\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8616\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8614\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8611\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8619\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8622\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8618\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8611\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8633\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8622\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8633\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3382 - accuracy: 0.8620\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8627\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8639\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8624\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8645\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8648\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8629\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8650\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8633\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8640\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8646\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3340 - accuracy: 0.8637\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8621\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8636\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8633\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8631\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.8635\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3327 - accuracy: 0.8651\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8640\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8646\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8641\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3327 - accuracy: 0.8645\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8648\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8635\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8629\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8644\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8606\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8624\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8652\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8631\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8619\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8641\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8633\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8631\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8634\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8648\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8661\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8621\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3294 - accuracy: 0.8645\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8651\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3297 - accuracy: 0.8654\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8636\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8626\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8644\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8637\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8636\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8652\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8636\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8640\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8634\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8651\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8637\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8649\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8654\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3283 - accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.8645\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.8627\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history_deep = ann_deep.fit(X_train, y_train, batch_size = 32, epochs = 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5d974ae-dfd2-4139-81a9-e4fbbddde2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate deeper model\n",
    "y_pred_deep = ann_deep.predict(X_test)\n",
    "y_pred_deep = (y_pred_deep > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94d26c35-c763-4cfa-af72-5c4abe86b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_deep = confusion_matrix(y_test, y_pred_deep)\n",
    "acc_deep = accuracy_score(y_test, y_pred_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1459dba-3fae-479a-9262-b1fe809017bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Deeper ANN):\n",
      " [[1493  102]\n",
      " [ 185  220]]\n",
      "Accuracy (Deeper ANN): 0.8565\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix (Deeper ANN):\\n\", cm_deep)\n",
    "print(\"Accuracy (Deeper ANN):\", acc_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2154e-b626-4cf8-8bae-91205a50550b",
   "metadata": {},
   "source": [
    "## We now add 3 hidden layers and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa0dea3c-3045-4b64-986f-9e1dc3fff1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8a6c426-4d44-48d0-9b38-733f42659982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input + Hidden Layers\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be8d6c64-391b-4b44-86d2-70bffa3f7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5570dad2-4d09-4c72-9df9-cbca0ec257cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5243 - accuracy: 0.7841\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.7966\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4363 - accuracy: 0.8109\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4244 - accuracy: 0.8170\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4158 - accuracy: 0.8192\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4072 - accuracy: 0.8227\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8290\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.8390\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8460\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3600 - accuracy: 0.8480\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3551 - accuracy: 0.8520\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3519 - accuracy: 0.8544\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3500 - accuracy: 0.8549\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3488 - accuracy: 0.8570\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3478 - accuracy: 0.8561\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8580\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8600\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8595\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8599\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8621\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.8612\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8597\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8611\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8615\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3389 - accuracy: 0.8624\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8624\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8624\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8626\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3376 - accuracy: 0.8625\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8624\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8627\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8636\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8624\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8635\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8636\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8629\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8641\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8629\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8637\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8654\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8660\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8636\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8639\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8658\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8666\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8656\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8655\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.8673\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8649\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8631\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3319 - accuracy: 0.8662\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8662\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8659\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8659\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8659\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8675\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3313 - accuracy: 0.8656\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8654\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8651\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8668\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8680\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8655\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8662\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8668\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8661\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8668\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8666\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.8670\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.8676\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8670\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8656\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8669\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3296 - accuracy: 0.8671\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8669\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8664\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8665\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8666\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8670\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8659\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3297 - accuracy: 0.8658\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8670\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8655\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8665\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8664\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8659\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8670\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3287 - accuracy: 0.8668\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8660\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8665\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8677\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.8673\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8677\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3290 - accuracy: 0.8683\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3284 - accuracy: 0.8668\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8665\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8676\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3278 - accuracy: 0.8669\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8662\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3284 - accuracy: 0.8673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2315f1b3a60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and Train\n",
    "ann.compile(optimizer='adam', \n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f91d4d84-06fb-4e08-93b0-39ea0a09799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred = (ann.predict(X_test) > 0.5)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "225de4fc-0956-40d5-85d1-cf1b5b2a2a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (3 Hidden Layers):\n",
      "[[1512   83]\n",
      " [ 196  209]]\n",
      "Accuracy (3 Hidden Layers): 0.8605\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix (3 Hidden Layers):\")\n",
    "print(cm)\n",
    "print(\"Accuracy (3 Hidden Layers):\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75f6ee-42f2-4c92-aca0-1a8c75e2ad30",
   "metadata": {},
   "source": [
    "#  Comparison of Models\n",
    "\n",
    "We experimented with **different ANN architectures** (1, 2, and 3 hidden layers) and compared their performance.\n",
    "\n",
    "\n",
    "\n",
    "##  Results Summary\n",
    "\n",
    "| ANN Architecture   | Confusion Matrix                | Accuracy |\n",
    "|--------------------|---------------------------------|----------|\n",
    "| **1 Hidden Layer** | [[1492  103] <br> [ 186  219]] | **0.8555** |\n",
    "| **2 Hidden Layers**| [[1525   70] <br> [ 198  207]] | **0.8660** |\n",
    "| **3 Hidden Layers**| [[1526   69] <br> [ 210  195]] | **0.8605** |\n",
    "\n",
    "\n",
    "##  Interpretation\n",
    "\n",
    "- **Hidden Layer:**  \n",
    "  - Accuracy: ~85.5%  \n",
    "  - Performs reasonably well, but leaves some misclassifications.  \n",
    "\n",
    "- **Hidden Layers:**  \n",
    "  - Accuracy: ~86.6%  \n",
    "  - Best overall performance in terms of accuracy.  \n",
    "  - Fewer false positives compared to 1 hidden layer.  \n",
    "\n",
    "- **Hidden Layers:**  \n",
    "  - Accuracy: ~86.0%  \n",
    "  - Slightly worse than 2 layers, indicating **adding more layers did not help**.  \n",
    "  - More false negatives (customers leaving were predicted as staying).  \n",
    "\n",
    "\n",
    "##  Conclusion\n",
    "\n",
    "- Increasing from **1 â†’ 2 hidden layers** improved performance.  \n",
    "- Adding a **3rd hidden layer** did **not** improve accuracy â€” in fact, performance dropped slightly.  \n",
    "- **Best Model:** ANN with **2 hidden layers**, giving **~86.6% accuracy**.  \n",
    "-  More layers are not always better â€” they may cause **overfitting** or unnecessary complexity.  \n",
    "- To further improve performance, we should explore:  \n",
    "  - **Hyperparameter tuning** (units per layer, learning rate, batch size).  \n",
    "  - **Regularization techniques** (Dropout, L2).  \n",
    "  - **Feature engineering** (new features, removing noisy ones).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48513c02-3ee7-4d34-9946-bc96b6716781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
